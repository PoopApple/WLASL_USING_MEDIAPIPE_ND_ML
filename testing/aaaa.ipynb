{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e412e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aca25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f28b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "def process_video(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Process a video with Mediapipe Pose + Hands.\n",
    "    Draws skeleton and hand landmarks, saves to output_path.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"❌ Could not open {input_path}\")\n",
    "        return\n",
    "\n",
    "    # Setup output video writer\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=2)\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pose_results = pose.process(image_rgb)\n",
    "        hand_results = hands.process(image_rgb)\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw pose\n",
    "        if pose_results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image_bgr,\n",
    "                pose_results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "            )\n",
    "\n",
    "        # Draw hands\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image_bgr,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "                )\n",
    "\n",
    "        out.write(image_bgr)\n",
    "\n",
    "    pose.close()\n",
    "    hands.close()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"✅ Processed and saved: {output_path}\")\n",
    "\n",
    "def process_multiple_videos(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Runs Mediapipe processing on all videos in a folder.\n",
    "    Saves outputs to output_folder with same filenames.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, f\"processed_{filename}\")\n",
    "            process_video(input_path, output_path)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"vids\"           # your folder containing raw videos\n",
    "    output_folder = \"landmarked\"  # folder for processed outputs\n",
    "    process_multiple_videos(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# landmark indices from mediapipe pose model\n",
    "FACE_POINTS = {\n",
    "    \"nose\": 0,\n",
    "    \"left_eye\": 2,\n",
    "    \"right_eye\": 5,\n",
    "    \"mouth_left\": 9,\n",
    "    \"mouth_right\": 10\n",
    "}\n",
    "\n",
    "def process_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"❌ Could not open {input_path}\")\n",
    "        return\n",
    "\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    pose = mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=2,\n",
    "        smooth_landmarks=True,\n",
    "        min_detection_confidence=0.3,\n",
    "        min_tracking_confidence=0.3\n",
    "    )\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.3,\n",
    "        min_tracking_confidence=0.3\n",
    "    )\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pose_results = pose.process(image_rgb)\n",
    "        hand_results = hands.process(image_rgb)\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        \n",
    "        frame_landmarks = []\n",
    "\n",
    "        # ----- Pose landmarks (33 points) -----\n",
    "        if pose_results.pose_landmarks:\n",
    "            for lm in pose_results.pose_landmarks.landmark:\n",
    "                frame_landmarks.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "        else:\n",
    "            frame_landmarks.extend([0.0] * (33*4))  # pad if not detected\n",
    "\n",
    "        # ----- Minimal face points (5 points) -----\n",
    "        if pose_results.pose_landmarks:\n",
    "            for idx in FACE_POINTS.values():\n",
    "                lm = pose_results.pose_landmarks.landmark[idx]\n",
    "                frame_landmarks.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "        else:\n",
    "            frame_landmarks.extend([0.0] * (5*4))\n",
    "\n",
    "        # ----- Hands (21 landmarks per hand, 2 hands) -----\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    frame_landmarks.extend([lm.x, lm.y, lm.z, 1.0])\n",
    "        # if no hands detected, pad for 2 hands\n",
    "        if not hand_results.multi_hand_landmarks:\n",
    "            frame_landmarks.extend([0.0] * (21*2*4))\n",
    "\n",
    "        # Add to overall list\n",
    "        all_frames.append(frame_landmarks)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Draw pose landmarks (body)\n",
    "        if pose_results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image_bgr,\n",
    "                pose_results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "            )\n",
    "\n",
    "            # Draw minimal face points (eyes, nose, mouth)\n",
    "            h, w, _ = image_bgr.shape\n",
    "            for name, idx in FACE_POINTS.items():\n",
    "                lm = pose_results.pose_landmarks.landmark[idx]\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                cv2.circle(image_bgr, (x, y), 5, (0, 255, 255), -1)\n",
    "                # cv2.putText(image_bgr, name, (x + 5, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "        # Draw hands\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image_bgr,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "                )\n",
    "\n",
    "        out.write(image_bgr)\n",
    "\n",
    "    pose.close()\n",
    "    hands.close()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"✅ Processed and saved: {output_path}\")\n",
    "\n",
    "def process_multiple_videos(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    # ip = [\"00335.mp4\",\"00\"]\n",
    "    \n",
    "    \n",
    "    # return\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, f\"processed_{filename}\")\n",
    "            process_video(input_path, output_path)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"vids\"           # your folder containing raw videos\n",
    "    output_folder = \"landmarked\"  # folder for processed outputs\n",
    "    process_multiple_videos(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71e5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0cf8c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 Playing videos. Press Ctrl+C in terminal to stop.\n",
      "\n",
      "🛑 Stopped by user.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# minimal face points from Pose model\n",
    "FACE_POINTS = [0, 2, 5, 9, 10]\n",
    "\n",
    "def play_videos_loop(input_folder):\n",
    "    pose = mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=2,\n",
    "        smooth_landmarks=True,\n",
    "        min_detection_confidence=0.3,\n",
    "        min_tracking_confidence=0.3\n",
    "    )\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.3,\n",
    "        min_tracking_confidence=0.3\n",
    "    )\n",
    "\n",
    "    video_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.mp4', '.mov', '.avi', '.mkv'))]\n",
    "    if not video_files:\n",
    "        print(\"❌ No video files found\")\n",
    "        return\n",
    "\n",
    "    print(\"🎥 Playing videos. Press Ctrl+C in terminal to stop.\")\n",
    "\n",
    "    try:\n",
    "        while True:  # infinite loop\n",
    "            for filename in video_files:\n",
    "                cap = cv2.VideoCapture(os.path.join(input_folder, filename))\n",
    "                if not cap.isOpened():\n",
    "                    print(f\"❌ Could not open {filename}\")\n",
    "                    continue\n",
    "\n",
    "                while cap.isOpened():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "\n",
    "                    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    pose_results = pose.process(image_rgb)\n",
    "                    hand_results = hands.process(image_rgb)\n",
    "                    image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    # Pose landmarks\n",
    "                    if pose_results.pose_landmarks:\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                            image_bgr,\n",
    "                            pose_results.pose_landmarks,\n",
    "                            mp_pose.POSE_CONNECTIONS,\n",
    "                            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "                        )\n",
    "                        # minimal face points\n",
    "                        h, w, _ = image_bgr.shape\n",
    "                        for idx in FACE_POINTS:\n",
    "                            lm = pose_results.pose_landmarks.landmark[idx]\n",
    "                            x, y = int(lm.x * w), int(lm.y * h)\n",
    "                            cv2.circle(image_bgr, (x, y), 5, (0, 255, 255), -1)\n",
    "\n",
    "                    # Hands\n",
    "                    if hand_results.multi_hand_landmarks:\n",
    "                        for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                            mp_drawing.draw_landmarks(\n",
    "                                image_bgr,\n",
    "                                hand_landmarks,\n",
    "                                mp_hands.HAND_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "                            )\n",
    "\n",
    "                    cv2.imshow(\"Landmarks Viewer\", image_bgr)\n",
    "                    if cv2.waitKey(1) & 0xFF == 27:  # ESC key to skip video\n",
    "                        break\n",
    "\n",
    "                cap.release()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 Stopped by user.\")\n",
    "\n",
    "    pose.close()\n",
    "    hands.close()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    play_videos_loop(\"vids\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTTTTT FULL\n",
    "\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# minimal face landmark indices from pose model\n",
    "FACE_POINTS = [0, 2, 5, 9, 10]\n",
    "\n",
    "def extract_landmarks_from_video(video_path):\n",
    "    pose = mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=2,\n",
    "        smooth_landmarks=True,\n",
    "        min_detection_confidence=0.3,\n",
    "        min_tracking_confidence=0.3\n",
    "    )\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.3,\n",
    "        min_tracking_confidence=0.3\n",
    "    )\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    all_frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pose_results = pose.process(image_rgb)\n",
    "        hand_results = hands.process(image_rgb)\n",
    "\n",
    "        frame_data = []\n",
    "\n",
    "        # ----- Pose landmarks (torso + limbs) -----\n",
    "        if pose_results.pose_landmarks:\n",
    "            for lm in pose_results.pose_landmarks.landmark:\n",
    "                frame_data.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "        else:\n",
    "            frame_data.extend([0.0] * (33 * 4))  # fill missing with zeros\n",
    "\n",
    "        # ----- Minimal face points -----\n",
    "        if pose_results.pose_landmarks:\n",
    "            for idx in FACE_POINTS:\n",
    "                lm = pose_results.pose_landmarks.landmark[idx]\n",
    "                frame_data.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "        else:\n",
    "            frame_data.extend([0.0] * (len(FACE_POINTS) * 4))\n",
    "\n",
    "        # ----- Hands -----\n",
    "        for hand_landmarks in (hand_results.multi_hand_landmarks or []):\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                frame_data.extend([lm.x, lm.y, lm.z, 1.0])\n",
    "        # if no hand detected, pad for 2 hands (21 landmarks each)\n",
    "        if not hand_results.multi_hand_landmarks:\n",
    "            frame_data.extend([0.0] * (21 * 2 * 4))\n",
    "\n",
    "        all_frames.append(frame_data)\n",
    "\n",
    "    cap.release()\n",
    "    pose.close()\n",
    "    hands.close()\n",
    "\n",
    "    return np.array(all_frames, dtype=np.float32)\n",
    "\n",
    "\n",
    "def process_videos_to_numpy(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename.replace('.', '_') + \".npy\")\n",
    "\n",
    "            landmarks = extract_landmarks_from_video(input_path)\n",
    "            np.save(output_path, landmarks)\n",
    "            print(f\"✅ Saved {output_path} with shape {landmarks.shape}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    process_videos_to_numpy(\"videos\", \"landmark_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda04085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe setup\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Minimal face points from pose landmarks\n",
    "FACE_POINTS = {\n",
    "    \"nose\": 0,\n",
    "    \"left_eye\": 2,\n",
    "    \"right_eye\": 5,\n",
    "    \"mouth_left\": 9,\n",
    "    \"mouth_right\": 10\n",
    "}\n",
    "\n",
    "def process_video(input_path, output_folder):\n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"❌ Could not open {input_path}\")\n",
    "        return\n",
    "\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Prepare output video path\n",
    "    base_name = os.path.basename(input_path)\n",
    "    video_out_path = os.path.join(output_folder, f\"processed_{base_name}\")\n",
    "    npy_out_path   = os.path.join(output_folder, f\"{os.path.splitext(base_name)[0]}.npy\")\n",
    "\n",
    "    out = cv2.VideoWriter(video_out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    # Initialize Mediapipe models\n",
    "    pose = mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=2,\n",
    "        smooth_landmarks=True,\n",
    "        min_detection_confidence=0.3,\n",
    "        min_tracking_confidence=0.3\n",
    "    )\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.3,\n",
    "        min_tracking_confidence=0.3\n",
    "    )\n",
    "\n",
    "    all_frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert BGR → RGB\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pose_results = pose.process(image_rgb)\n",
    "        hand_results = hands.process(image_rgb)\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw pose landmarks\n",
    "        if pose_results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image_bgr,\n",
    "                pose_results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "            )\n",
    "\n",
    "            # Draw minimal face points\n",
    "            h, w, _ = image_bgr.shape\n",
    "            for idx in FACE_POINTS.values():\n",
    "                lm = pose_results.pose_landmarks.landmark[idx]\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                cv2.circle(image_bgr, (x, y), 5, (0, 255, 255), -1)\n",
    "\n",
    "        # Draw hands\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image_bgr,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "                )\n",
    "\n",
    "        # ----- Extract landmarks for ML -----\n",
    "        frame_landmarks = []\n",
    "\n",
    "        # Pose landmarks (33)\n",
    "        if pose_results.pose_landmarks:\n",
    "            for lm in pose_results.pose_landmarks.landmark:\n",
    "                frame_landmarks.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "        else:\n",
    "            frame_landmarks.extend([0.0]*(33*4))\n",
    "\n",
    "        # Minimal face points (5)\n",
    "        if pose_results.pose_landmarks:\n",
    "            for idx in FACE_POINTS.values():\n",
    "                lm = pose_results.pose_landmarks.landmark[idx]\n",
    "                frame_landmarks.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "        else:\n",
    "            frame_landmarks.extend([0.0]*(5*4))\n",
    "\n",
    "        # Hands (2 hands x 21 landmarks)\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    frame_landmarks.extend([lm.x, lm.y, lm.z, 1.0])\n",
    "        # pad if no hands detected\n",
    "        if not hand_results.multi_hand_landmarks:\n",
    "            frame_landmarks.extend([0.0]*(21*2*4))\n",
    "\n",
    "        all_frames.append(frame_landmarks)\n",
    "\n",
    "        # Write frame to output video\n",
    "        out.write(image_bgr)\n",
    "\n",
    "    # Cleanup\n",
    "    pose.close()\n",
    "    hands.close()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Save landmarks as numpy file\n",
    "    all_frames_np = np.array(all_frames, dtype=np.float32)\n",
    "    np.save(npy_out_path, all_frames_np)\n",
    "\n",
    "    print(f\"✅ Processed: {video_out_path}\")\n",
    "    print(f\"✅ Landmarks saved: {npy_out_path} (shape={all_frames_np.shape})\")\n",
    "\n",
    "\n",
    "def process_multiple_videos(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            process_video(input_path, output_folder)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"vids\"           # folder with raw videos\n",
    "    output_folder = \"landmarked\"    # folder for videos + landmarks\n",
    "    process_multiple_videos(input_folder, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
